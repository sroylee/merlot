{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import urllib\n",
    "import re\n",
    "import math\n",
    "import sys\n",
    "import io\n",
    "import random\n",
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set connection to mySQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='10.0.106.71', \n",
    "                             user='roylee', \n",
    "                             password='LARCuser4848', \n",
    "                             db='roylee',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the base users from file\n",
    "- i_file: input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_file = 'data/SOGH_users.csv'\n",
    "so_gh_users = {}\n",
    "gh_so_users = {}\n",
    "\n",
    "with open(i_file) as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        ghid = str(row[0])\n",
    "        soid = str(row[1])\n",
    "        so_gh_users[soid] = ghid\n",
    "        gh_so_users[ghid] = soid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get watch activity data from mySQL\n",
    "- i_start_date: start date for the range of data retrieved\n",
    "- i_end_date: end date for the range of data retrieved\n",
    "- o_groudtruth_file: user-watch activity file\n",
    "- o_repo_file: watched repository with the description tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_start_date = ''\n",
    "i_end_date = ''\n",
    "o_groundtruth_file = ''\n",
    "o_repo_file= ''\n",
    "\n",
    "try:\n",
    "    with open(o_groundtruth_file, 'a+') as fout:\n",
    "        with connection.cursor() as cursor:\n",
    "            count = 0\n",
    "            base_watch_repos = {}\n",
    "            for key, value in gh_so_users.items():\n",
    "                sql = \"SELECT ownerid, repoid, watcherid, tags FROM sb_ghwatcher WHERE watcherid='\"+key+ \n",
    "                \"' AND create_at>='\"+i_start_date+\n",
    "                \"' AND create_at<'\"+i_end_date+\"'\"\n",
    "                \n",
    "                cursor.execute(sql)\n",
    "                result = cursor.fetchall()\n",
    "                for line in result:\n",
    "                    ownerid = line['ownerid']\n",
    "                    repoid = line['repoid']\n",
    "                    watcherid = line['watcherid']\n",
    "                    tags = line['tags'].strip()\n",
    "                    if tags != 'null':\n",
    "                        fout.writelines(watcherid +','+ repoid + '\\n')\n",
    "                        base_watch_repos[repoid] = tags\n",
    "                count += 1\n",
    "                print(count)\n",
    "    with open(o_repo_file, 'a+') as fout:\n",
    "        for key, value in base_watch_repos.items():\n",
    "            fout.writelines( key +','+ value + '\\n')\n",
    "finally:\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Get fork activity data from mySQL\n",
    "- i_start_date: start date for the range of data retrieved\n",
    "- i_end_date: end date for the range of data retrieved\n",
    "- o_groudtruth_file: user-fork activity file\n",
    "- o_repo_file: forked repository with the description tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_start_date = ''\n",
    "i_end_date = ''\n",
    "o_groundtruth_file = ''\n",
    "o_repo_file= ''\n",
    "\n",
    "try:\n",
    "    with open(o_groundtruth_file, 'a+') as fout:\n",
    "        with connection.cursor() as cursor:\n",
    "            count = 0\n",
    "            base_fork_repos = {}\n",
    "            for key, value in gh_so_users.items():\n",
    "                sql = \"SELECT ownerid, repoid, tags FROM sb_ghfork WHERE ownerid='\"+key+\n",
    "                \"' AND create_at>='\"+i_start_date+\n",
    "                \"' AND create_at<'\"+i_end_date+\"'\"\n",
    "                \n",
    "                cursor.execute(sql)\n",
    "                result = cursor.fetchall()\n",
    "                for line in result:\n",
    "                    ownerid = line['ownerid']\n",
    "                    repoid = line['repoid']\n",
    "                    tags = line['tags'].strip()\n",
    "                    if tags != 'null':\n",
    "                        fout.writelines(ownerid +','+ repoid + '\\n')\n",
    "                        base_fork_repos[repoid] = tags\n",
    "                count += 1\n",
    "                print(count)\n",
    "    with open(o_repo_file, 'a+') as fout:\n",
    "        for key, value in base_fork_repos.items():\n",
    "            fout.writelines(key +','+ value + '\\n')\n",
    "finally:\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get answer activity data from mySQL\n",
    "- i_start_date: start date for the range of data retrieved\n",
    "- i_end_date: end date for the range of data retrieved\n",
    "- o_groudtruth_file: user-answer activity file\n",
    "- o_qn_file: answered question with the description tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_start_date = ''\n",
    "i_end_date = ''\n",
    "o_groundtruth_file = ''\n",
    "o_qn_file= ''\n",
    "\n",
    "try:\n",
    "    with open(o_groundtruth_file, 'a+') as fout:\n",
    "        with connection.cursor() as cursor:\n",
    "            count = 0\n",
    "            base_answer_questions = {}\n",
    "            for key, value in gh_so_users.items():\n",
    "                sql = \"SELECT ownerid, parentid, tags FROM sb_soanswer WHERE ownerid='\"+value+\n",
    "                \"' AND create_at>='\"+i_start_date+\n",
    "                \"' AND create_at<'\"+i_end_date+\"'\"\n",
    "                \n",
    "                cursor.execute(sql)\n",
    "                result = cursor.fetchall()\n",
    "                for line in result:\n",
    "                    ownerid = line['ownerid']\n",
    "                    qnid = line['parentid']\n",
    "                    tags = line['tags'].strip()\n",
    "                    if tags != 'null':\n",
    "                        fout.writelines(ownerid +','+ qnid + '\\n')\n",
    "                        base_answer_questions[qnid] = tags\n",
    "                count += 1\n",
    "                print(count)\n",
    "    with open(o_qn_file, 'a+') as fout:\n",
    "        for key, value in base_answer_questions.items():\n",
    "            fout.writelines(key +','+ value + '\\n')\n",
    "finally:\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get favorite activity data from mySQL\n",
    "- i_start_date: start date for the range of data retrieved\n",
    "- i_end_date: end date for the range of data retrieved\n",
    "- o_groudtruth_file: user-favorite activity file\n",
    "- o_qn_file: favorited question with the description tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_start_date = ''\n",
    "i_end_date = ''\n",
    "o_groundtruth_file = ''\n",
    "o_qn_file= ''\n",
    "\n",
    "try:\n",
    "    with open(o_groundtruth_file, 'a+') as fout:\n",
    "        with connection.cursor() as cursor:\n",
    "            count = 0\n",
    "            base_favorite_questions = {}\n",
    "            for key, value in gh_so_users.items():\n",
    "                sql = \"SELECT ownerid, parentid, tags FROM sb_sofavorite WHERE ownerid='\"+value+\n",
    "                \"' AND create_at>='\"+i_start_date+\n",
    "                \"' AND create_at<'\"+i_end_date+\"'\"\n",
    "                \n",
    "                cursor.execute(sql)\n",
    "                result = cursor.fetchall()\n",
    "                for line in result:\n",
    "                    ownerid = line['ownerid']\n",
    "                    qnid = line['parentid']\n",
    "                    tags = line['tags'].strip()\n",
    "                    if tags != 'null':\n",
    "                        fout.writelines(ownerid +','+ qnid + '\\n')\n",
    "                        base_favorite_questions[qnid] = tags\n",
    "                count += 1\n",
    "                print(count)\n",
    "    with open(o_qn_file, 'a+') as fout:\n",
    "        for key, value in base_favorite_questions.items():\n",
    "            fout.writelines(key +','+ value + '\\n')\n",
    "finally:\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate GitHub training/testing data\n",
    "This generate the positive and negative activity instances for each user.\n",
    "- i_groundtruth_file: user-activity file\n",
    "- i_repo_file: activity repository with the description tags\n",
    "- o_data_file: output data file\n",
    "- n: number of negative instances = n * number of positive instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_groundtruth_file = '' \n",
    "i_repo_file = '' \n",
    "o_data_file = ''\n",
    "n = 5\n",
    "\n",
    "user_repo_pos_count = {}\n",
    "user_repo_neg_count = {}\n",
    "pos_data = []\n",
    "neg_data = []\n",
    "repos = []\n",
    "\n",
    "for key, value in gh_so_users.items():\n",
    "    user_repo_pos_count[key] = 0\n",
    "\n",
    "with open(i_repo_file) as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        repoid = str(row[0])\n",
    "        repos.append(repoid)\n",
    "\n",
    "with open(i_groundtruth_file) as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        ghid = str(row[0])\n",
    "        repoid = str(row[1])\n",
    "        user_repo_pos_count[ghid] = user_repo_pos_count[ghid] + 1\n",
    "        pos_data.append(ghid+','+repoid)\n",
    "\n",
    "for key,value in user_repo_pos_count.items():\n",
    "    user_repo_neg_count[key] = value * n\n",
    "\n",
    "count = 0\n",
    "for key,value in user_repo_neg_count.items():\n",
    "    ghid = key\n",
    "    while value != 0:\n",
    "        candidate = random.choice(repos)\n",
    "        neg_choice = ghid+','+candidate\n",
    "        if neg_choice not in pos_data:\n",
    "            neg_data.append(neg_choice)\n",
    "            value -= 1\n",
    "    count += 1\n",
    "    print(count)\n",
    "    \n",
    "with open(o_data_file, 'a+') as fout:\n",
    "    for item in pos_data:\n",
    "        fout.writelines(item +',1'+'\\n')\n",
    "    for item in neg_data:\n",
    "        fout.writelines(item +',-1'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Stack Overflow training/testing data\n",
    "This generate the positive and negative activity instances for each user.\n",
    "- i_groundtruth_file: user-activity file\n",
    "- i_qn_file: activity question with the description tags\n",
    "- o_data_file: output data file\n",
    "- n: number of negative instances = n * number of positive instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_groundtruth_file = '' \n",
    "i_qn_file = '' \n",
    "o_data_file = ''\n",
    "n = 5\n",
    "\n",
    "user_qn_pos_count = {}\n",
    "user_qn_neg_count = {}\n",
    "pos_data = []\n",
    "neg_data = []\n",
    "qns = []\n",
    "\n",
    "for key, value in gh_so_users.items():\n",
    "    user_qn_pos_count[value] = 0\n",
    "\n",
    "\n",
    "with open(i_qn_file) as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        qnid = str(row[0])\n",
    "        qns.append(qnid)\n",
    "\n",
    "with open(i_groundtruth_file) as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        soid = str(row[0])\n",
    "        qnid = str(row[1])\n",
    "        user_qn_pos_count[soid] = user_qn_pos_count[soid] + 1\n",
    "        pos_data.append(soid+','+qnid)\n",
    "\n",
    "for key,value in user_qn_pos_count.items():\n",
    "    user_qn_neg_count[key] = value * 5\n",
    "\n",
    "count = 0\n",
    "for key,value in user_qn_neg_count.items():\n",
    "    soid = key\n",
    "    while value != 0:\n",
    "        candidate = random.choice(qns)\n",
    "        neg_choice = soid+','+candidate\n",
    "        if neg_choice not in pos_data:\n",
    "            neg_data.append(neg_choice)\n",
    "            value -= 1\n",
    "    count += 1\n",
    "    print(count)\n",
    "    \n",
    "with open(o_data_file, 'a+') as fout:\n",
    "    for item in pos_data:\n",
    "        fout.writelines(item +',1'+'\\n')\n",
    "    for item in neg_data:\n",
    "        fout.writelines(item +',-1'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the user activity distribution\n",
    "- i_fork_file: input user-fork activity file\n",
    "- i_watch_file: input user-watch activity file\n",
    "- i_answer_file: input user-answer activity file\n",
    "- i_favorite_file: input user-favorite activity file\n",
    "- o_dist_file: output user distribution file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_fork_file = 'toy_data/user_fork_repository.csv'\n",
    "i_watch_file = 'toy_data/user_watch_repository.csv'\n",
    "i_answer_file = 'toy_data/user_answer_question.csv'\n",
    "i_favorite_file = 'toy_data/user_favorite_question.csv'\n",
    "o_dist_file = 'toy_data/user_activity_distribution.csv'\n",
    "\n",
    "so_dist = {} #soid,answer_count,fav_count\n",
    "gh_dist = {} #ghid,fork_count,watch_count\n",
    "\n",
    "for key, value in gh_so_users.items():\n",
    "    so_dist[value] = [0,0]\n",
    "    gh_dist[key] = [0,0]\n",
    "    \n",
    "with open(i_fork_file) as f:\n",
    "    reader = csv.reader(f,delimiter=',')\n",
    "    for row in reader:\n",
    "        uid = str(row[0])\n",
    "        gh_dist[uid][0] += 1\n",
    "\n",
    "with open(i_watch_file) as f:\n",
    "    reader = csv.reader(f,delimiter=',')\n",
    "    for row in reader:\n",
    "        uid = str(row[0])\n",
    "        gh_dist[uid][1] += 1\n",
    "\n",
    "with open(i_answer_file) as f:\n",
    "    reader = csv.reader(f,delimiter=',')\n",
    "    for row in reader:\n",
    "        uid = str(row[0])\n",
    "        so_dist[uid][0] += 1\n",
    "\n",
    "with open(i_favorite_file) as f:\n",
    "    reader = csv.reader(f,delimiter=',')\n",
    "    for row in reader:\n",
    "        uid = str(row[0])\n",
    "        so_dist[uid][1] += 1\n",
    "\n",
    "with open(o_dist_file, 'a+') as fout:\n",
    "    for key, value in gh_so_users.items():\n",
    "        fout.writelines(str(key) +','+ \n",
    "            str(value) +','+ \n",
    "            str(gh_dist[key][0]) +','+\n",
    "            str(gh_dist[key][1]) +','+\n",
    "            str(so_dist[value][0]) +','+\n",
    "            str(so_dist[value][1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the user-activity distribution\n",
    "- i_user_dist_file: the user distribution file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gh_id</th>\n",
       "      <th>so_id</th>\n",
       "      <th>fork_count</th>\n",
       "      <th>watch_count</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.623900e+04</td>\n",
       "      <td>4.623900e+04</td>\n",
       "      <td>46239.000000</td>\n",
       "      <td>46239.000000</td>\n",
       "      <td>46239.000000</td>\n",
       "      <td>46239.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.037569e+05</td>\n",
       "      <td>8.805124e+05</td>\n",
       "      <td>3.702199</td>\n",
       "      <td>18.190164</td>\n",
       "      <td>11.762819</td>\n",
       "      <td>4.359458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.940880e+05</td>\n",
       "      <td>7.345248e+05</td>\n",
       "      <td>8.399300</td>\n",
       "      <td>69.868085</td>\n",
       "      <td>67.255959</td>\n",
       "      <td>25.402997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.443965e+05</td>\n",
       "      <td>2.371610e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.297700e+05</td>\n",
       "      <td>6.978560e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.122494e+06</td>\n",
       "      <td>1.393410e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.579459e+06</td>\n",
       "      <td>2.736012e+06</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>4939.000000</td>\n",
       "      <td>3959.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              gh_id         so_id    fork_count   watch_count  answer_count  \\\n",
       "count  4.623900e+04  4.623900e+04  46239.000000  46239.000000  46239.000000   \n",
       "mean   7.037569e+05  8.805124e+05      3.702199     18.190164     11.762819   \n",
       "std    6.940880e+05  7.345248e+05      8.399300     69.868085     67.255959   \n",
       "min    2.000000e+00  1.000000e+00      0.000000      0.000000      0.000000   \n",
       "25%    1.443965e+05  2.371610e+05      0.000000      0.000000      0.000000   \n",
       "50%    4.297700e+05  6.978560e+05      1.000000      2.000000      1.000000   \n",
       "75%    1.122494e+06  1.393410e+06      4.000000     11.000000      5.000000   \n",
       "max    7.579459e+06  2.736012e+06    448.000000   4939.000000   3959.000000   \n",
       "\n",
       "       favorite_count  \n",
       "count    46239.000000  \n",
       "mean         4.359458  \n",
       "std         25.402997  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          1.000000  \n",
       "max       2730.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_user_dist_file = 'data/user_activity_distribution.csv'\n",
    "\n",
    "df = pd.read_csv(i_user_dist_file, header=None)\n",
    "df.columns = ['gh_id','so_id','fork_count','watch_count','answer_count','favorite_count']\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformat data into new format\n",
    "- i_user_references: reference for users's GitHub and Stack Overflow user ids\n",
    "- i_user_answer: user's answer activities (old format)\n",
    "- i_user_favorite = user's favorite activities (old format)\n",
    "- i_user_fork = user's fork activities (old format)\n",
    "- i_user_watch = user's watch activities (old format)\n",
    "- i_answer_tag = tags for answered questions\n",
    "- i_favorite_tag = tags for favorited questions\n",
    "- i_fork_tag = tags for forked repositories\n",
    "- i_watch_tag = tags for watched repositories\n",
    "- o_user_answer = output file for user's answer activities\n",
    "- o_user_favorite = output file for user's favorite activities\n",
    "- o_user_fork = output file for user's fork activities\n",
    "- o_user_watch = output file for user's watch activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_user_references = 'toy_data/new_format/user_references.csv'\n",
    "i_user_answer = 'toy_data/user_answer_question.csv'\n",
    "i_user_favorite = 'toy_data/user_favorite_question.csv'\n",
    "i_user_fork = 'toy_data/user_fork_repository.csv'\n",
    "i_user_watch = 'toy_data/user_watch_repository.csv'\n",
    "i_answer_tag = 'toy_data/question_answer_tag.csv'\n",
    "i_favorite_tag = 'toy_data/question_favorite_tag.csv'\n",
    "i_fork_tag = 'toy_data/repository_fork_tag.csv'\n",
    "i_watch_tag = 'toy_data/repository_watch_tag.csv'\n",
    "o_user_answer = 'toy_data/new_format/user_answer_activities.csv'\n",
    "o_user_favorite = 'toy_data/new_format/user_favorite_activities.csv'\n",
    "o_user_fork = 'toy_data/new_format/user_fork_activities.csv'\n",
    "o_user_watch = 'toy_data/new_format/user_watch_activities.csv'\n",
    "\n",
    "gh_uid = {}\n",
    "so_uid = {}\n",
    "with open(i_user_references, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        uid = int(row[0])\n",
    "        ghid = str(row[1])\n",
    "        soid = str(row[2])\n",
    "        gh_uid[ghid] = uid\n",
    "        so_uid[soid] = uid\n",
    "\n",
    "qn_tags = {}\n",
    "with open(i_answer_tag, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        qid = str(row[0])\n",
    "        tags = str(row[1])\n",
    "        tags = tags.replace(' ; ',' ')\n",
    "        qn_tags[qid] = tags\n",
    "        \n",
    "with open(i_favorite_tag, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        qid = str(row[0])\n",
    "        tags = str(row[1])\n",
    "        tags = tags.replace(' ; ',' ')\n",
    "        qn_tags[qid] = tags\n",
    "        \n",
    "repo_tags = {}\n",
    "with open(i_fork_tag, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        rid = str(row[0])\n",
    "        tags = str(row[1])\n",
    "        tags = tags.replace(' ; ',' ')\n",
    "        repo_tags[rid] = tags\n",
    "        \n",
    "with open(i_watch_tag, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        rid = str(row[0])\n",
    "        tags = str(row[1])\n",
    "        tags = tags.replace(' ; ',' ')\n",
    "        repo_tags[rid] = tags\n",
    "        \n",
    "with open(o_user_answer, 'a+') as fout:\n",
    "    with open(i_user_answer, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            soid = str(row[0])\n",
    "            qid = str(row[1])\n",
    "            uid = so_uid[soid]\n",
    "            tags = qn_tags[qid]\n",
    "            fout.writelines(str(uid) +','+ str(qid) +','+ str(tags) + '\\n')\n",
    "        \n",
    "with open(o_user_favorite, 'a+') as fout:\n",
    "    with open(i_user_favorite, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            soid = str(row[0])\n",
    "            qid = str(row[1])\n",
    "            uid = so_uid[soid]\n",
    "            tags = qn_tags[qid]\n",
    "            fout.writelines(str(uid) +','+ str(qid) +','+ str(tags) + '\\n')\n",
    "\n",
    "with open(o_user_fork, 'a+') as fout:\n",
    "    with open(i_user_fork, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            ghid = str(row[0])\n",
    "            rid = str(row[1])\n",
    "            uid = gh_uid[ghid]\n",
    "            tags = repo_tags[rid]\n",
    "            fout.writelines(str(uid) +','+ str(rid) +','+ str(tags) + '\\n')\n",
    "\n",
    "with open(o_user_watch, 'a+') as fout:\n",
    "    with open(i_user_watch, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            ghid = str(row[0])\n",
    "            rid = str(row[1])\n",
    "            uid = gh_uid[ghid]\n",
    "            tags = repo_tags[rid]\n",
    "            fout.writelines(str(uid) +','+ str(rid) +','+ str(tags) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genenerate Training and Test set\n",
    "- i_users: user file\n",
    "- i_activities: user activity file\n",
    "- o_training_activities: output training file for the activity\n",
    "- o_testing_activities: output test file for the activity\n",
    "- percentage_train: percentage of user activities used for traning\n",
    "- nNegative: Number of negative instances, which is the n times of positive instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_users = 'toy_data/new_format/users.csv'\n",
    "i_activities = 'toy_data/new_format/user_favorite_activities.csv'\n",
    "o_training_activities = 'toy_data/new_format/training/user_favorite_training.csv'\n",
    "o_testing_activities = 'toy_data/new_format/test/user_favorite_testing.csv'\n",
    "percentage_train = 0.8\n",
    "nNegative = 5\n",
    "\n",
    "user_acitivity_counts = {}\n",
    "user_activities = {}\n",
    "user_non_activities = {}\n",
    "with open(i_users, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        uid = int(row[0])       \n",
    "        user_acitivity_counts[uid] = 0\n",
    "        user_activities[uid] = []\n",
    "        user_non_activities[uid] = []\n",
    "\n",
    "all_activities = []\n",
    "activity_tags = {}\n",
    "with open(i_activities, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        uid = int(row[0])\n",
    "        rid = str(row[1])\n",
    "        tags = str(row[2])\n",
    "        user_acitivity_counts[uid] += 1\n",
    "        user_activities[uid].append(rid)\n",
    "        all_activities.append(rid)\n",
    "        activity_tags[rid] = tags\n",
    "\n",
    "for key,value in user_non_activities.items():\n",
    "    user_non_activities[key] = list(set(all_activities)-set(user_activities[key]))\n",
    "       \n",
    "user_training_count_pos = {}\n",
    "user_training_count_neg = {}\n",
    "user_test_count_neg = {}\n",
    "for key, value in user_acitivity_counts.items():\n",
    "    user_training_count_pos[key] = int(math.ceil(user_acitivity_counts[key] * percentage_train))\n",
    "    \n",
    "    #if it is bigger than all the possible non-links\n",
    "    if (value * nNegative) > len(user_non_activities[key]):\n",
    "        user_training_count_neg[key] = int(math.ceil(len(user_non_activities[key]) * percentage_train))\n",
    "        user_test_count_neg[key] = int(math.floor(len(user_non_activities[key]) * (1-percentage_train)))\n",
    "    else:\n",
    "        user_training_count_neg[key] = int(math.ceil(user_acitivity_counts[key] * percentage_train) * nNegative)\n",
    "        user_test_count_neg[key] = int(math.floor(user_acitivity_counts[key] * (1-percentage_train)) * nNegative)\n",
    "\n",
    "#Generate positive training and test instances\n",
    "with open(o_training_activities, 'a+') as ftrain:\n",
    "    with open(o_testing_activities, 'a+') as ftest:\n",
    "        with open(i_activities, encoding='utf-8') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            for row in reader:\n",
    "                uid = int(row[0])\n",
    "                rid = str(row[1])\n",
    "                tags = str(row[2])\n",
    "                if user_training_count_pos[uid] > 0:\n",
    "                    ftrain.writelines(str(uid) +','+ str(rid) +','+ str(tags) + ',1\\n')\n",
    "                    user_training_count_pos[uid] -= 1\n",
    "                else:\n",
    "                    ftest.writelines(str(uid) +','+ str(rid) +','+ str(tags) + ',1\\n')\n",
    "\n",
    "#Generate negative training instances\n",
    "with open(o_training_activities, 'a+') as ftrain:\n",
    "    for key, value in user_training_count_neg.items():\n",
    "        random.shuffle(user_non_activities[key])\n",
    "        for i in range(0,value):\n",
    "            rid = user_non_activities[key].pop()\n",
    "            tags = activity_tags[rid]\n",
    "            ftrain.writelines(str(key) +','+ str(rid) +','+ str(tags) +',0 \\n')\n",
    "            \n",
    "#Generate negative test instances\n",
    "with open(o_testing_activities, 'a+') as ftest:\n",
    "    for key, value in user_test_count_neg.items():\n",
    "        random.shuffle(user_non_activities[key])\n",
    "        for i in range(0,value):\n",
    "            rid = user_non_activities[key].pop()\n",
    "            tags = activity_tags[rid]\n",
    "            ftest.writelines(str(key) +','+ str(rid) +','+ str(tags) +',0 \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity Similarity Feature: Similary between query item and user's activities\n",
    "Given a query item $q$ (i.e., a Stack Overflow question or GitHub repository) and a user $u$, we compute averange similarity between $q$ and all items where $u$ has perform an activity $a$ on. For example, given an item question $q_1$, we compute the average similarity $q_1$ and all other questions where beween user $u_1$ has answered. I.e., in this case, the activity $a$ will be the *answer* activity. The similarity function is given as below: \n",
    "\n",
    "$Sim(u,q,a) = \\frac{|\\{i\\in I_{(u,a)}|i_{tags}\\in q_{tags}\\}|}{|I_{(u,a)}|}$\n",
    "\n",
    "Where, $<u,q,a>$ is a triplet of a user $u$, query item $q$ and specific activity $a$. We say that a query item $q$ is similar to a user $u$'s $a$ activities, when many items, which $u$ performed $a$ on, shares similar tags with $q$. The above similarity function captures this intuition. The numerator computes the number of items where $u$ perform $a$ and the item shares at least 1 tag with the query item $q$. The denominator computes the total number of items where $u$ perform $a$\n",
    "\n",
    "Notations\n",
    "- $u$: User\n",
    "- $a$: Activity. Different activities performed by user. E.g. answer, favorite, fork and watch.\n",
    "- $i$: Item, i.e., Stack Overflow question or GitHub repository\n",
    "- $q$: Query item\n",
    "- $I_{(u,a)}$: Items where user $u$ perform activity $a$ on. E.g. questions which are answered by a user. \n",
    "- $i_{tags}$: Tags for the item. E.g. *Java*, *iOS*, etc. \n",
    "- $q_{tags}$: Tags for query item.\n",
    "\n",
    "For function UserActivitySim():\n",
    "- q: query item id (str)\n",
    "- I_ua: ids of items where user has perform an activity (list)\n",
    "- I_tags: key is item id and value is tags (dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserActivitySim(q, I_ua, I_tags):\n",
    "    if q in I_ua:\n",
    "        I_ua.remove(q)\n",
    "    if len(I_ua)==0:\n",
    "        return 0\n",
    "    q_tags = set(I_tags[q].split(' '))\n",
    "    numerator = 0\n",
    "    for i in I_ua:\n",
    "        i_tags = set(I_tags[i].split(' '))\n",
    "        overlap = i_tags.intersection(q_tags)\n",
    "        if len(overlap) >0:\n",
    "            numerator += 1\n",
    "    return numerator/len(I_ua)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We use [Mean Average Precision (MAP)](https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173) to evaluate the activity prediciton tasks. I.e., we take total average precision (AP) of each user divided by the total number of users. \n",
    "\n",
    "MAP function:\n",
    "- groundtruth: a dictionary where key is user id and value is the test labels for all the positive/negative instance for this use\n",
    "- pred: a dictionary where key is the user id and value is the predicted probabilities of the label being posititive (i.e,'1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(groundtruth,pred):\n",
    "    result = 0\n",
    "    for key, value in groundtruth.items():\n",
    "        y_truth = value\n",
    "        y_pred = pred[key]\n",
    "        score= average_precision_score(y_truth,y_pred)\n",
    "        result +=score\n",
    "    return result/len(groundtruth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Activity Prediction \n",
    "#### Setup 1: Using only Answer Similarity Feature\n",
    "- Compute the similarity scores for answer training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_users = 'toy_data/new_format/users.csv'\n",
    "i_training_activities = 'toy_data/new_format/training/user_answer_training.csv'\n",
    "i_testing_activities = 'toy_data/new_format/test/user_answer_testing.csv'\n",
    "\n",
    "#Load answer training set\n",
    "ans_u_ids_train = []\n",
    "ans_q_ids_train = []\n",
    "ans_q_label_train = []\n",
    "ans_user_items_train = {} \n",
    "ans_item_tags_train = {}\n",
    "with open(i_training_activities, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        uid = int(row[0])\n",
    "        rid = str(row[1])\n",
    "        tags = str(row[2])\n",
    "        label = int(row[3])\n",
    "        ans_u_ids_train.append(uid)\n",
    "        ans_q_ids_train.append(rid)\n",
    "        ans_q_label_train.append(label)\n",
    "        if label==1:\n",
    "            if uid in ans_user_items_train:\n",
    "                ans_user_items_train[uid].append(rid)\n",
    "            else:\n",
    "                ans_user_items_train[uid] = [rid]\n",
    "        ans_item_tags_train[rid] = tags\n",
    "\n",
    "#Compute score for answer training set\n",
    "ans_scores_train = []\n",
    "for i in range(len(ans_u_ids_train)):\n",
    "    q = ans_q_ids_train[i]\n",
    "    uid = ans_u_ids_train[i]\n",
    "    I_ua = ans_user_items_train[uid].copy()\n",
    "    I_tags = ans_item_tags_train\n",
    "    score = UserActivitySim(q, I_ua, I_tags)\n",
    "    ans_scores_train.append(score)\n",
    "    \n",
    "#Load answer test set\n",
    "ans_u_ids_test = []\n",
    "ans_q_ids_test = []\n",
    "ans_q_label_test = []\n",
    "ans_user_items_test = {} \n",
    "ans_item_tags_test = {}\n",
    "with open(i_testing_activities, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        uid = int(row[0])\n",
    "        rid = str(row[1])\n",
    "        tags = str(row[2])\n",
    "        label = int(row[3])\n",
    "        ans_u_ids_test.append(uid)\n",
    "        ans_q_ids_test.append(rid)\n",
    "        ans_q_label_test.append(label)\n",
    "        if label==1:\n",
    "            if uid in ans_user_items_test:\n",
    "                ans_user_items_test[uid].append(rid)\n",
    "            else:\n",
    "                ans_user_items_test[uid] = [rid]\n",
    "        ans_item_tags_test[rid] = tags\n",
    "\n",
    "#Compute score for answer test set\n",
    "ans_scores_test = []\n",
    "for i in range(len(ans_u_ids_test)):\n",
    "    q = ans_q_ids_test[i]\n",
    "    uid = ans_u_ids_test[i]\n",
    "    I_ua = ans_user_items_test[uid].copy()\n",
    "    I_tags = ans_item_tags_test\n",
    "\n",
    "    score = UserActivitySim(q, I_ua, I_tags)\n",
    "    ans_scores_test.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "x_train_list = []\n",
    "for i in range(len(ans_scores_train)):\n",
    "    x_train_list.append([int(ans_u_ids_train[i]),int(ans_scores_train[i])])\n",
    "x_train = np.array(x_train_list)\n",
    "y_train = ans_q_label_train.copy()\n",
    "clf = svm.SVC(kernel='linear',probability=True)\n",
    "#clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train_list,y_train)\n",
    "\n",
    "#Testing\n",
    "x_test_list = []\n",
    "for i in range(len(ans_scores_test)):\n",
    "    x_test_list.append([int(ans_u_ids_test[i]),int(ans_scores_test[i])])\n",
    "x_test = np.array(x_test_list)\n",
    "y_test = ans_q_label_test.copy()\n",
    "pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-191-9d4e2d594ba5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0muid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mans_u_ids_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muid\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muser_level_pred\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0muser_level_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0muser_level_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "user_level_truth = {}\n",
    "user_level_pred = {}\n",
    "for i in range(len(pred)):\n",
    "    uid = ans_u_ids_test[i]\n",
    "    if uid not in user_level_pred:\n",
    "        user_level_pred[uid] = [pred[i][0]]\n",
    "    else:\n",
    "        user_level_pred[uid].append(pred[i][1])\n",
    "\n",
    "for i in range(len(ans_q_label_test)):\n",
    "    uid = ans_u_ids_test[i]\n",
    "    if uid not in user_level_truth:\n",
    "        user_level_truth[uid] = [ans_q_label_test[i]]\n",
    "    else:\n",
    "        user_level_truth[uid].append(ans_q_label_test[i])\n",
    "\n",
    "result = MAP(user_level_truth,user_level_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
